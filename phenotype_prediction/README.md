# Type I Diabetes Prediction from Whole Shotgun Metagenome of Human Infant Gut

## Background
A somewhat recent IBM Research study [(Carrieri et al., 2019)](https://research.ibm.com/publications/a-fast-machine-learning-workflow-for-rapid-phenotype-prediction-from-whole-shotgun-metagenomes) introduces a process for rapid phenotype prediction from whole shotgun metagenomic data. It primarily makes use of a dimensionality reduction technique called [HULK (Histosketching Using Little K-mers)](https://github.com/will-rowe/hulk) as introduced by [Rowe et al. (2018)](https://www.biorxiv.org/content/10.1101/408070v1.full.pdf). Amusingly, it is one of many related tools named after Marvel characters. It provides a compact representation (in KB) of the whole metagenome (which is GB in magnitude) that can be utilised for classification tasks, acting as a feature vector for ML models. It extends the work of [Asgari et. al (2018)](https://pubmed.ncbi.nlm.nih.gov/30500871/) that showed the use of k-mer distributions outperforms Operational Taxonomic Units (OTU) as features. That is by utilising the whole shotgun metagenome rather than their 16S rRNA sequence.

Another study [(Kostic et al., 2015)](https://www.cell.com/cell-host-microbe/fulltext/S1931-3128(15)00021-9) explores the relationship between the progression of type I diabetes (T1D) with the gut microbiome diversity of infants. Notably, they have their [metagenomic sequence data publicly available](https://diabimmune.broadinstitute.org/diabimmune/t1d-cohort/resources/metagenomic-sequence-data). In total, there are 124 samples from 19 subjects collected at different periods as well as their T1D diagnosis. Using the relatively new technique of histosketching, I sought the viability of using prediction models for this use case.

## Methodology
Whole genome shotgun (WGS) sequences from the study carried out by [Kostic et al. (2015)](https://www.cell.com/cell-host-microbe/fulltext/S1931-3128(15)00021-9) are retrieved and pairs of paired-end FASTQ files are interleaved. These are then histosketched to produce feature vectors. LASSO is further employed to narrow down the selected features to those relevant. Classification models used parallel that of the IBM paper, namely: Relevance Vector Machines (RVM), Support Vector Machines (SVM), Random Forests (RF), and Naive Bayes (NB). Similarly, for their performance metrics, each is trained with 80% of the data and tested on the remaining 20% through 10-fold cross-validation (CV).


